{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":43317,"status":"ok","timestamp":1678467114129,"user":{"displayName":"Ukramarly","userId":"12331974385466066517"},"user_tz":300},"id":"9m-4-Fio-Ifh"},"outputs":[],"source":["!pip install --no-cache-dir transformers sentencepiece \u0026\u003e /dev/null \n","!pip install datasets \u0026\u003e /dev/null \n","!pip install evaluate \u0026\u003e /dev/null "]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1678467114130,"user":{"displayName":"Ukramarly","userId":"12331974385466066517"},"user_tz":300},"id":"Jkv5mfMw-KTJ"},"outputs":[],"source":["#from huggingface_hub import notebook_login\n","#notebook_login()"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2781,"status":"ok","timestamp":1678467116905,"user":{"displayName":"Ukramarly","userId":"12331974385466066517"},"user_tz":300},"id":"eV705O8V-kJb","outputId":"21bfd77e-85e5-44b4-80e7-64aa87cdd96e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cpu\n","\n"]}],"source":["import torch\n","# setting device on GPU if available, else CPU\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print('Using device:', device)\n","print()\n","\n","#Additional Info when using cuda\n","if device.type == 'cuda':\n","    print(torch.cuda.get_device_name(0))\n","    print('Memory Usage:')\n","    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n","    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1678467116906,"user":{"displayName":"Ukramarly","userId":"12331974385466066517"},"user_tz":300},"id":"_HUuBKYI-Bwo"},"outputs":[],"source":["data_folder = '/content/drive/MyDrive/UNLP/unlp-2023-shared-task-main/data/'\n","gec_fluency_valid_src = data_folder + 'gec-fluency/valid.src.txt'\n","gec_fluency_valid_tgt = data_folder + 'gec-fluency/valid.tgt.txt'\n","gec_only_valid_src = data_folder + 'gec-only/valid.src.txt'\n","gec_only_valid_tgt = data_folder + 'gec-only/valid.tgt.txt'"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":4684,"status":"ok","timestamp":1678467121586,"user":{"displayName":"Ukramarly","userId":"12331974385466066517"},"user_tz":300},"id":"utZRrggL95QT"},"outputs":[],"source":["import pandas as pd\n","from datasets import Dataset\n","\n","# reading the output data\n","with open(gec_fluency_valid_src, 'r') as f:\n","    valid_src = [line[:-1] for line in f.readlines()]\n","\n","with open(gec_fluency_valid_tgt, 'r') as f:\n","    valid_tgt = [line[:-1] for line in f.readlines()]\n","\n","# converting sentences to pandas dataframe\n","valid_sentences = [[valid_src[i], valid_tgt[i]] for i in range(len(valid_src))]\n","\n","valid_df = pd.DataFrame(valid_sentences)\n","valid_df.columns = ['source', 'target']\n","\n","valid_dataset = Dataset.from_pandas(valid_df)"]},{"cell_type":"markdown","metadata":{"id":"WpKYDPKEAJD1"},"source":["# Translator"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":411},"executionInfo":{"elapsed":140772,"status":"error","timestamp":1678467262355,"user":{"displayName":"Ukramarly","userId":"12331974385466066517"},"user_tz":300},"id":"6NYtwGPx-CF4","outputId":"46c8e794-89ee-4913-a5a3-40e59df0b9f9"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b52b5e61f244473890a45546896c909b","version_major":2,"version_minor":0},"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/1.41k [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0369340f42cb47f79e3e62898a37b547","version_major":2,"version_minor":0},"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/2.44G [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-6-901c266bb3dd\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Replace this with your own checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel_checkpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"StopFuture/future_13_2ep\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 5\u001b[0;31m \u001b[0mtranslator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"translation\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_lang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"uk_UA\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_lang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"uk_UA\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/pipelines/__init__.py\u001b[0m in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, framework, revision, use_fast, use_auth_token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m    826\u001b[0m                 \u001b[0mtokenizer_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 828\u001b[0;31m             tokenizer = AutoTokenizer.from_pretrained(\n\u001b[0m\u001b[1;32m    829\u001b[0m                 \u001b[0mtokenizer_identifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_fast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_fast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_from_pipeline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtokenizer_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;31m# Next, let's try to use the tokenizer_config file to get the tokenizer class.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 598\u001b[0;31m         \u001b[0mtokenizer_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_tokenizer_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"_commit_hash\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenizer_config\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mget_tokenizer_config\u001b[0;34m(pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, **kwargs)\u001b[0m\n\u001b[1;32m    440\u001b[0m     ```\"\"\"\n\u001b[1;32m    441\u001b[0m     \u001b[0mcommit_hash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 442\u001b[0;31m     resolved_config_file = cached_file(\n\u001b[0m\u001b[1;32m    443\u001b[0m         \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0mTOKENIZER_CONFIG_FILE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 409\u001b[0;31m         resolved_file = hf_hub_download(\n\u001b[0m\u001b[1;32m    410\u001b[0m             \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m             \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 120\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout)\u001b[0m\n\u001b[1;32m   1137\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 1139\u001b[0;31m                 metadata = get_hf_file_metadata(\n\u001b[0m\u001b[1;32m   1140\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m                     \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 120\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout)\u001b[0m\n\u001b[1;32m   1469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1470\u001b[0m     \u001b[0;31m# Retrieve metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 1471\u001b[0;31m     r = _request_wrapper(\n\u001b[0m\u001b[1;32m   1472\u001b[0m         \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HEAD\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m         \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, max_retries, base_wait_time, max_wait_time, timeout, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0;31m# 2. Force relative redirection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfollow_relative_redirects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 407\u001b[0;31m         response = _request_wrapper(\n\u001b[0m\u001b[1;32m    408\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, max_retries, base_wait_time, max_wait_time, timeout, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[0;31m# 3. Exponential backoff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 442\u001b[0;31m     return http_backoff(\n\u001b[0m\u001b[1;32m    443\u001b[0m         \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhttp_backoff\u001b[0;34m(method, url, max_retries, base_wait_time, max_wait_time, retry_on_exceptions, retry_on_status_codes, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;31m# Perform request and return if status_code is not in the retry list.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 129\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mretry_on_status_codes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    540\u001b[0m         }\n\u001b[1;32m    541\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 542\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 655\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 439\u001b[0;31m                 resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    440\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0;31m# Make the request on the httplib connection object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 703\u001b[0;31m             httplib_response = self._make_request(\n\u001b[0m\u001b[1;32m    704\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;31m# Trigger any extra validation we need to do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 386\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m             \u001b[0;31m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1040\u001b[0m         \u001b[0;31m# Force connect early to allow us to validate the connection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sock\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 1042\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_verified\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_default_certs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 414\u001b[0;31m         self.sock = ssl_wrap_socket(\n\u001b[0m\u001b[1;32m    415\u001b[0m             \u001b[0msock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m             \u001b[0mkeyfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/urllib3/util/ssl_.py\u001b[0m in \u001b[0;36mssl_wrap_socket\u001b[0;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msend_sni\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 449\u001b[0;31m         ssl_sock = _ssl_wrap_socket_impl(\n\u001b[0m\u001b[1;32m    450\u001b[0m             \u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtls_in_tls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/urllib3/util/ssl_.py\u001b[0m in \u001b[0;36m_ssl_wrap_socket_impl\u001b[0;34m(sock, ssl_context, tls_in_tls, server_hostname)\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 493\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mssl_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mssl_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.9/ssl.py\u001b[0m in \u001b[0;36mwrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0;31m# SSLSocket class handles server_hostname encoding before it calls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;31m# ctx._wrap_socket()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 501\u001b[0;31m         return self.sslsocket_class._create(\n\u001b[0m\u001b[1;32m    502\u001b[0m             \u001b[0msock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m             \u001b[0mserver_side\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_side\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.9/ssl.py\u001b[0m in \u001b[0;36m_create\u001b[0;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[1;32m   1039\u001b[0m                         \u001b[0;31m# non-blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"do_handshake_on_connect should not be specified for non-blocking sockets\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 1041\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.9/ssl.py\u001b[0m in \u001b[0;36mdo_handshake\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m   1308\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 1310\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1311\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1312\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["from transformers import pipeline\n","\n","# Replace this with your own checkpoint\n","model_checkpoint = \"StopFuture/future_13_2ep\"\n","translator = pipeline(\"translation\", src_lang=\"uk_UA\", tgt_lang=\"uk_UA\", model=model_checkpoint, device=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":12,"status":"aborted","timestamp":1678467262356,"user":{"displayName":"Ukramarly","userId":"12331974385466066517"},"user_tz":300},"id":"pvR7jWEn-gjS"},"outputs":[],"source":["output_sent = translator(valid_dataset['source'], batch_size=64)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":12,"status":"aborted","timestamp":1678467262356,"user":{"displayName":"Ukramarly","userId":"12331974385466066517"},"user_tz":300},"id":"ba_QwyOGAKq0"},"outputs":[],"source":["import os\n","model_name = model_checkpoint.split('/')[1]\n","\n","output_folder = f'/content/drive/MyDrive/UNLP/results/{model_name}'\n","\n","# creating the output folder\n","if not os.path.exists(output_folder):\n","  os.mkdir(output_folder)\n","\n","output_path = output_folder + '/output.txt'\n","\n","output_sentences = [sent['translation_text'] + '\\n' for sent in output_sent]\n","with open(output_path, 'w') as f:\n","  f.writelines(output_sentences)"]},{"cell_type":"markdown","metadata":{"id":"k_cxarnp9BQh"},"source":["# Analyzing results"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":3313,"status":"ok","timestamp":1678467287120,"user":{"displayName":"Ukramarly","userId":"12331974385466066517"},"user_tz":300},"id":"t2JZG6mbaBv4"},"outputs":[],"source":["import os\n","model_checkpoint = \"StopFuture/future_13_2ep\"\n","model_name = model_checkpoint.split('/')[1]\n","output_folder = f'/content/drive/MyDrive/UNLP/results/{model_name}'\n","\n","# creating the output folder\n","if not os.path.exists(output_folder):\n","  os.mkdir(output_folder)\n","\n","output_path = output_folder + '/output.txt'"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1678467287120,"user":{"displayName":"Ukramarly","userId":"12331974385466066517"},"user_tz":300},"id":"WGhCMGdLZCXf"},"outputs":[],"source":["corrected = output_path\n","m2 = '/content/drive/MyDrive/UNLP/unlp-2023-shared-task-main/data/gec-fluency/valid.m2'"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":51612,"status":"ok","timestamp":1678467338730,"user":{"displayName":"Ukramarly","userId":"12331974385466066517"},"user_tz":300},"id":"hPwhOSg4es_O","outputId":"c7eb58cd-cd7b-444e-d566-ac1cf2fcf246"},"outputs":[{"name":"stdout","output_type":"stream","text":["/bin/bash: 3: No such file or directory\n"]}],"source":["!pip install ua-gec==2.0.0 \u0026\u003e /dev/null\n","!pip install errant==2.3.3 \u0026\u003e /dev/null\n","!pip install spacy\u003e=2.2.0,\u003c3 \u0026\u003e /dev/null\n","!pip install stanza==1.4.2 \u0026\u003e /dev/null"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":425},"executionInfo":{"elapsed":101993,"status":"ok","timestamp":1678467440716,"user":{"displayName":"Ukramarly","userId":"12331974385466066517"},"user_tz":300},"id":"3_jzQDYVO4In","outputId":"e7763844-67c2-46d1-d885-9d0c3ee92214"},"outputs":[{"name":"stderr","output_type":"stream","text":["Tokenizing submission...\n","INFO:stanza:Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5ad8fc0c6cf94b3cbd36eb589ec67c70","version_major":2,"version_minor":0},"text/plain":["Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.1.json:   0%|   …"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["WARNING:stanza:Language uk package default expects mwt, which has been added\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8a6949354e804c43a0cb1609b100b008","version_major":2,"version_minor":0},"text/plain":["Downloading https://huggingface.co/stanfordnlp/stanza-uk/resolve/v1.4.1/models/tokenize/iu.pt:   0%|          …"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0139ccf77fef4c2bafcaf9b7d3fcf404","version_major":2,"version_minor":0},"text/plain":["Downloading https://huggingface.co/stanfordnlp/stanza-uk/resolve/v1.4.1/models/mwt/iu.pt:   0%|          | 0.0…"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO:stanza:Loading these models for language: uk (Ukrainian):\n","=======================\n","| Processor | Package |\n","-----------------------\n","| tokenize  | iu      |\n","| mwt       | iu      |\n","=======================\n","\n","INFO:stanza:Use device: cpu\n","INFO:stanza:Loading: tokenize\n","INFO:stanza:Loading: mwt\n","INFO:stanza:Done loading processors!\n","Tokenized: /tmp/unlp.target.tok\n","Downloading spacy resources...\n","Aligned submission: /content/drive/MyDrive/UNLP/results/future_13_2ep/unlp.target.m2\n"]}],"source":["import subprocess\n","import sys\n","import tempfile\n","from pathlib import Path\n","\n","import spacy\n","import stanza\n","\n","\n","def tokenize(text: str) -\u003e [str]:\n","    if not hasattr(tokenize, \"nlp\"):\n","        tokenize.nlp = stanza.Pipeline(lang=\"uk\", processors=\"tokenize\")\n","    nlp = tokenize.nlp\n","\n","    tokenized = \" \".join([t.text for t in nlp(text).iter_tokens()])\n","    return tokenized\n","\n","\n","def tokenize_file(input_file: Path, output_file: Path):\n","    with open(input_file, encoding=\"utf-8\") as f, open(output_file, \"w\", encoding=\"utf-8\") as out:\n","        for line in f:\n","            line = line.rstrip(\"\\n\")\n","            tokenized = tokenize(line)\n","            out.write(tokenized + \"\\n\")\n","\n","tmp = Path(tempfile.gettempdir())\n","print(\"Tokenizing submission...\", file=sys.stderr)\n","tokenized_path = tmp / f\"unlp.target.tok\"\n","tokenize_file(corrected, tokenized_path)\n","print(f\"Tokenized: {tokenized_path}\", file=sys.stderr)\n","\n","\n","try:\n","  spacy.load(\"en\")\n","except OSError:\n","  print(\"Downloading spacy resources...\", file=sys.stderr)\n","  subprocess.run([\"python\", \"-m\", \"spacy\", \"download\", \"en\"], check=True)\n","\n","  \n","# Get the source text out of m2\n","source_path = tmp / f\"unlp.source.tok\"\n","with open(m2, encoding=\"utf-8\") as f, open(source_path, \"w\", encoding=\"utf-8\") as out:\n","  for line in f:\n","    if line.startswith(\"S \"):\n","      out.write(line[2:])\n","\n","# Align tokenized submission with the original text with Errant\n","m2_target = output_folder + \"/unlp.target.m2\"\n","subprocess.run([\"errant_parallel\", \"-orig\", source_path, \"-cor\", tokenized_path, \"-out\", m2_target], check=True)\n","print(f\"Aligned submission: {m2_target}\", file=sys.stderr)"]},{"cell_type":"markdown","metadata":{"id":"P38z1_jME-Ea"},"source":["# Filter"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":23,"status":"ok","timestamp":1678467440716,"user":{"displayName":"Ukramarly","userId":"12331974385466066517"},"user_tz":300},"id":"eii4IouhJDtP"},"outputs":[],"source":["import pandas as pd"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1557,"status":"ok","timestamp":1678467442252,"user":{"displayName":"Ukramarly","userId":"12331974385466066517"},"user_tz":300},"id":"6yVT8noFLqI6","outputId":"e5dad472-938d-4add-9083-4e298ea15234"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u003cipython-input-12-43fea6ed0c22\u003e:41: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  sent_df[edit[0]][i] += 1\n","\u003cipython-input-12-43fea6ed0c22\u003e:42: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  sent_df[f'ref{edit[1]}'][i] +=1\n"]}],"source":["with open(m2_target, 'r') as f:\n","  sentences = f.read().split('\\n\\n')[:-1]\n","\n","sentence_split = []\n","for sentence in sentences:\n","  sentence_split.append(sentence.split('\\n'))\n","\n","sent_df = []\n","for sent in sentence_split:\n","\n","  edits = []\n","  for edit in sent[1:]:\n","    edit_lst = edit.split('|||')\n","    edit_type = edit_lst[1]\n","    ref = edit_lst[-1]\n","\n","    edits.append([edit_type, ref])\n","  sent_dict = {'sent':sent[0], \n","               'all':sent, \n","               'total-edits':len(sent)-1,\n","               'all-edits':edits}\n","  sent_df.append(sent_dict)\n","sent_df = pd.DataFrame(sent_df)\n","\n","big_edits = []\n","for edits in sent_df['all-edits']:\n","  for edit in edits:\n","    big_edits.append(edit[0])\n","\n","all_cats = list(set(big_edits))\n","\n","for cat in all_cats:\n","  sent_df[cat] = 0\n","\n","sent_df['ref0'] = 0\n","sent_df['ref1'] = 0\n","\n","for i in range(len(sent_df)):\n","  edits = sent_df['all-edits'][i]\n","  for edit in edits:\n","    sent_df[edit[0]][i] += 1\n","    sent_df[f'ref{edit[1]}'][i] +=1\n","\n","drop_idx = list(sent_df[sent_df['total-edits']\u003e4].index)"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":286},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1678467442253,"user":{"displayName":"Ukramarly","userId":"12331974385466066517"},"user_tz":300},"id":"Z299BpYjDllT","outputId":"f41b84e8-ae5d-4b3e-c88b-ff1f2277c715"},"outputs":[{"data":{"text/html":["\n","  \u003cdiv id=\"df-9907f1f9-9cd2-40cd-94bc-5431e3da4f19\"\u003e\n","    \u003cdiv class=\"colab-df-container\"\u003e\n","      \u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003esent\u003c/th\u003e\n","      \u003cth\u003eall\u003c/th\u003e\n","      \u003cth\u003etotal-edits\u003c/th\u003e\n","      \u003cth\u003eall-edits\u003c/th\u003e\n","      \u003cth\u003eR:WO\u003c/th\u003e\n","      \u003cth\u003eM:NOUN\u003c/th\u003e\n","      \u003cth\u003eM:PUNCT\u003c/th\u003e\n","      \u003cth\u003eR:ORTH\u003c/th\u003e\n","      \u003cth\u003eM:OTHER\u003c/th\u003e\n","      \u003cth\u003eU:PREP\u003c/th\u003e\n","      \u003cth\u003e...\u003c/th\u003e\n","      \u003cth\u003eR:PUNCT\u003c/th\u003e\n","      \u003cth\u003eU:PUNCT\u003c/th\u003e\n","      \u003cth\u003eR:OTHER\u003c/th\u003e\n","      \u003cth\u003eR:DET\u003c/th\u003e\n","      \u003cth\u003eR:NOUN\u003c/th\u003e\n","      \u003cth\u003eR:VERB\u003c/th\u003e\n","      \u003cth\u003eU:NOUN\u003c/th\u003e\n","      \u003cth\u003eref0\u003c/th\u003e\n","      \u003cth\u003eref1\u003c/th\u003e\n","      \u003cth\u003epunct-edits\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e43\u003c/th\u003e\n","      \u003ctd\u003eS Очерет ставав все густіший - що з однієї сто...\u003c/td\u003e\n","      \u003ctd\u003e[S Очерет ставав все густіший - що з однієї ст...\u003c/td\u003e\n","      \u003ctd\u003e7\u003c/td\u003e\n","      \u003ctd\u003e[[R:SPELL, 0], [R:SPELL, 0], [R:PUNCT, 0], [M:...\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e2\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e7\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e2\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e178\u003c/th\u003e\n","      \u003ctd\u003eS Розглянемо типовий приклад в самому центрі м...\u003c/td\u003e\n","      \u003ctd\u003e[S Розглянемо типовий приклад в самому центрі ...\u003c/td\u003e\n","      \u003ctd\u003e5\u003c/td\u003e\n","      \u003ctd\u003e[[R:SPELL, 0], [R:OTHER, 0], [R:OTHER, 0], [R:...\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e3\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e5\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e280\u003c/th\u003e\n","      \u003ctd\u003eS Отжу я поклав бутилку ліків в портфель та пі...\u003c/td\u003e\n","      \u003ctd\u003e[S Отжу я поклав бутилку ліків в портфель та п...\u003c/td\u003e\n","      \u003ctd\u003e4\u003c/td\u003e\n","      \u003ctd\u003e[[R:NOUN, 0], [R:NOUN, 0], [R:NOUN, 0], [R:SPE...\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e3\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e4\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003cp\u003e3 rows × 26 columns\u003c/p\u003e\n","\u003c/div\u003e\n","      \u003cbutton class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9907f1f9-9cd2-40cd-94bc-5431e3da4f19')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\"\u003e\n","        \n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\"\u003e\n","    \u003cpath d=\"M0 0h24v24H0V0z\" fill=\"none\"/\u003e\n","    \u003cpath d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/\u003e\u003cpath d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/\u003e\n","  \u003c/svg\u003e\n","      \u003c/button\u003e\n","      \n","  \u003cstyle\u003e\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  \u003c/style\u003e\n","\n","      \u003cscript\u003e\n","        const buttonEl =\n","          document.querySelector('#df-9907f1f9-9cd2-40cd-94bc-5431e3da4f19 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-9907f1f9-9cd2-40cd-94bc-5431e3da4f19');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '\u003ca target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb\u003edata table notebook\u003c/a\u003e'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      \u003c/script\u003e\n","    \u003c/div\u003e\n","  \u003c/div\u003e\n","  "],"text/plain":["                                                  sent  \\\n","43   S Очерет ставав все густіший - що з однієї сто...   \n","178  S Розглянемо типовий приклад в самому центрі м...   \n","280  S Отжу я поклав бутилку ліків в портфель та пі...   \n","\n","                                                   all  total-edits  \\\n","43   [S Очерет ставав все густіший - що з однієї ст...            7   \n","178  [S Розглянемо типовий приклад в самому центрі ...            5   \n","280  [S Отжу я поклав бутилку ліків в портфель та п...            4   \n","\n","                                             all-edits  R:WO  M:NOUN  M:PUNCT  \\\n","43   [[R:SPELL, 0], [R:SPELL, 0], [R:PUNCT, 0], [M:...     0       0        1   \n","178  [[R:SPELL, 0], [R:OTHER, 0], [R:OTHER, 0], [R:...     0       0        1   \n","280  [[R:NOUN, 0], [R:NOUN, 0], [R:NOUN, 0], [R:SPE...     0       0        0   \n","\n","     R:ORTH  M:OTHER  U:PREP  ...  R:PUNCT  U:PUNCT  R:OTHER  R:DET  R:NOUN  \\\n","43        0        0       0  ...        1        0        2      0       1   \n","178       0        0       0  ...        0        0        3      0       0   \n","280       0        0       0  ...        0        0        0      0       3   \n","\n","     R:VERB  U:NOUN  ref0  ref1  punct-edits  \n","43        0       0     7     0            2  \n","178       0       0     5     0            1  \n","280       0       0     4     0            0  \n","\n","[3 rows x 26 columns]"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["sent_df['punct-edits'] = sent_df['M:PUNCT'] +  sent_df['R:PUNCT'] + sent_df['U:PUNCT']\n","drop_df = sent_df[sent_df['total-edits']-sent_df['punct-edits']\u003e3]\n","drop_df"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1678467442253,"user":{"displayName":"Ukramarly","userId":"12331974385466066517"},"user_tz":300},"id":"GH_ON6llEFNF"},"outputs":[],"source":["drop_idx = list(drop_df.index)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1678467442253,"user":{"displayName":"Ukramarly","userId":"12331974385466066517"},"user_tz":300},"id":"f3dyi626EV2u","outputId":"53e861cf-d2dc-46b6-f830-f6c7dee9aa66"},"outputs":[{"data":{"text/plain":["[43, 178, 280]"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["drop_idx"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1678467442817,"user":{"displayName":"Ukramarly","userId":"12331974385466066517"},"user_tz":300},"id":"zVlFlP4wFCh6"},"outputs":[],"source":["with open(output_path, 'r') as f:\n","  output_sentences = [sent[:-1] for sent in f.readlines()]\n","\n","data_folder = '/content/drive/MyDrive/UNLP/unlp-2023-shared-task-main/data/'\n","gec_fluency_valid_src = data_folder + 'gec-fluency/valid.src.txt'\n","\n","with open(gec_fluency_valid_src, 'r') as f:\n","  valid_src = [line[:-1] for line in f.readlines()]"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1678467442817,"user":{"displayName":"Ukramarly","userId":"12331974385466066517"},"user_tz":300},"id":"m2kjsVe-FZaJ"},"outputs":[],"source":["for id in drop_idx:\n","  output_sentences[id] = valid_src[id]"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":322,"status":"ok","timestamp":1678467443136,"user":{"displayName":"Ukramarly","userId":"12331974385466066517"},"user_tz":300},"id":"_PG07lFAFsRV"},"outputs":[],"source":["output_sentences = [sent + '\\n' for sent in output_sentences]\n","with open(output_path[:-4]+\"filter.txt\", 'w') as f:\n","  f.writelines(output_sentences)"]},{"cell_type":"markdown","metadata":{"id":"TZsPhMFXIu06"},"source":["#### Analyzing results"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":1128,"status":"ok","timestamp":1678467737195,"user":{"displayName":"Ukramarly","userId":"12331974385466066517"},"user_tz":300},"id":"4V-_rkNXIu06"},"outputs":[],"source":["import os\n","model_checkpoint = \"StopFuture/future_13_2ep\"\n","model_name = model_checkpoint.split('/')[1]\n","output_folder = f'/content/drive/MyDrive/UNLP/results/{model_name}'\n","filter_path = output_folder + '/outputfilter.txt'"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1678467738284,"user":{"displayName":"Ukramarly","userId":"12331974385466066517"},"user_tz":300},"id":"0dfLOZ2aIu06"},"outputs":[],"source":["corrected = filter_path\n","m2 = '/content/drive/MyDrive/UNLP/unlp-2023-shared-task-main/data/gec-fluency/valid.m2'"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":344},"executionInfo":{"elapsed":68822,"status":"ok","timestamp":1678467808758,"user":{"displayName":"Ukramarly","userId":"12331974385466066517"},"user_tz":300},"id":"N3EV8U3iIu06","outputId":"c13a7844-fd2d-477c-936f-a2890135eaa2"},"outputs":[{"name":"stderr","output_type":"stream","text":["Tokenizing submission...\n","INFO:stanza:Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1935352a0bdf4b989fc8150f0d69225b","version_major":2,"version_minor":0},"text/plain":["Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.1.json:   0%|   …"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["WARNING:stanza:Language uk package default expects mwt, which has been added\n","INFO:stanza:Loading these models for language: uk (Ukrainian):\n","=======================\n","| Processor | Package |\n","-----------------------\n","| tokenize  | iu      |\n","| mwt       | iu      |\n","=======================\n","\n","INFO:stanza:Use device: cpu\n","INFO:stanza:Loading: tokenize\n","INFO:stanza:Loading: mwt\n","INFO:stanza:Done loading processors!\n","Tokenized: /tmp/unlp.target.tok\n","Aligned submission: /content/drive/MyDrive/UNLP/results/future_13_2ep/filter.target.m2\n"]}],"source":["import subprocess\n","import sys\n","import tempfile\n","from pathlib import Path\n","\n","import spacy\n","import stanza\n","\n","\n","def tokenize(text: str) -\u003e [str]:\n","    if not hasattr(tokenize, \"nlp\"):\n","        tokenize.nlp = stanza.Pipeline(lang=\"uk\", processors=\"tokenize\")\n","    nlp = tokenize.nlp\n","\n","    tokenized = \" \".join([t.text for t in nlp(text).iter_tokens()])\n","    return tokenized\n","\n","\n","def tokenize_file(input_file: Path, output_file: Path):\n","    with open(input_file, encoding=\"utf-8\") as f, open(output_file, \"w\", encoding=\"utf-8\") as out:\n","        for line in f:\n","            line = line.rstrip(\"\\n\")\n","            tokenized = tokenize(line)\n","            out.write(tokenized + \"\\n\")\n","\n","tmp = Path(tempfile.gettempdir())\n","print(\"Tokenizing submission...\", file=sys.stderr)\n","tokenized_path = tmp / f\"unlp.target.tok\"\n","tokenize_file(corrected, tokenized_path)\n","print(f\"Tokenized: {tokenized_path}\", file=sys.stderr)\n","\n","\n","try:\n","  spacy.load(\"en\")\n","except OSError:\n","  print(\"Downloading spacy resources...\", file=sys.stderr)\n","  subprocess.run([\"python\", \"-m\", \"spacy\", \"download\", \"en\"], check=True)\n","\n","  \n","# Get the source text out of m2\n","source_path = tmp / f\"unlp.source.tok\"\n","with open(m2, encoding=\"utf-8\") as f, open(source_path, \"w\", encoding=\"utf-8\") as out:\n","  for line in f:\n","    if line.startswith(\"S \"):\n","      out.write(line[2:])\n","\n","# Align tokenized submission with the original text with Errant\n","m2_target_filter = output_folder + \"/filter.target.m2\"\n","subprocess.run([\"errant_parallel\", \"-orig\", source_path, \"-cor\", tokenized_path, \"-out\", m2_target_filter], check=True)\n","print(f\"Aligned submission: {m2_target_filter}\", file=sys.stderr)"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1678467808759,"user":{"displayName":"Ukramarly","userId":"12331974385466066517"},"user_tz":300},"id":"2Y6PL9mjSitg"},"outputs":[],"source":["class Args():\n","  def __init__(self):\n","    self.hyp = m2_target_filter\n","    self.ref = m2\n","    self.ds = False\n","    self.dt = False\n","    self.single = False\n","    self.multi = False\n","    self.filt = []\n","    self.cse = False\n","    self.verbose = False # SET THIS TO TRUE TO SEE SENTENCE INFO\n","    self.beta = 0.5\n","    self.cat = 3\n","args = Args()"]},{"cell_type":"markdown","metadata":{"id":"hHC3rFh8hmxy"},"source":["#### Evaluate script"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1678467808759,"user":{"displayName":"Ukramarly","userId":"12331974385466066517"},"user_tz":300},"id":"iQKtY2CVPecb"},"outputs":[],"source":["from collections import Counter\n","\n","# Input: An m2 format sentence with edits.\n","# Output: A list of lists. Each edit: [start, end, cat, cor, coder]\n","def simplify_edits(sent):\n","    out_edits = []\n","    # Get the edit lines from an m2 block.\n","    edits = sent.split(\"\\n\")[1:]\n","    # Loop through the edits\n","    for edit in edits:\n","        # Preprocessing\n","        edit = edit[2:].split(\"|||\") # Ignore \"A \" then split.\n","        span = edit[0].split()\n","        start = int(span[0])\n","        end = int(span[1])\n","        cat = edit[1]\n","        cor = edit[2]\n","        coder = int(edit[-1])\n","        out_edit = [start, end, cat, cor, coder]\n","        out_edits.append(out_edit)\n","    return out_edits\n","\n","# Input 1: A list of edits. Each edit: [start, end, cat, cor, coder]\n","# Input 2: Command line args\n","# Output: A dict; key is coder, value is edit dict.\n","def process_edits(edits, args):\n","    coder_dict = {}\n","    # Add an explicit noop edit if there are no edits.\n","    if not edits: edits = [[-1, -1, \"noop\", \"-NONE-\", 0]]\n","    # Loop through the edits\n","    for edit in edits:\n","        # Name the edit elements for clarity\n","        start = edit[0]\n","        end = edit[1]\n","        cat = edit[2]\n","        cor = edit[3]\n","        coder = edit[4]\n","        # Add the coder to the coder_dict if necessary\n","        if coder not in coder_dict: coder_dict[coder] = {}\n","\n","        # Optionally apply filters based on args\n","        # 1. UNK type edits are only useful for detection, not correction.\n","        if not args.dt and not args.ds and cat == \"UNK\": continue\n","        # 2. Only evaluate single token edits; i.e. 0:1, 1:0 or 1:1\n","        if args.single and (end-start \u003e= 2 or len(cor.split()) \u003e= 2): continue\n","        # 3. Only evaluate multi token edits; i.e. 2+:n or n:2+\n","        if args.multi and end-start \u003c 2 and len(cor.split()) \u003c 2: continue\n","        # 4. If there is a filter, ignore the specified error types\n","        if args.filt and cat in args.filt: continue\n","\n","        # Token Based Detection\n","        if args.dt:\n","            # Preserve noop edits.\n","            if start == -1:\n","                if (start, start) in coder_dict[coder].keys():\n","                    coder_dict[coder][(start, start)].append(cat)\n","                else:\n","                    coder_dict[coder][(start, start)] = [cat]\n","            # Insertions defined as affecting the token on the right\n","            elif start == end and start \u003e= 0:\n","                if (start, start+1) in coder_dict[coder].keys():\n","                    coder_dict[coder][(start, start+1)].append(cat)\n","                else:\n","                    coder_dict[coder][(start, start+1)] = [cat]\n","            # Edit spans are split for each token in the range.\n","            else:\n","                for tok_id in range(start, end):\n","                    if (tok_id, tok_id+1) in coder_dict[coder].keys():\n","                        coder_dict[coder][(tok_id, tok_id+1)].append(cat)\n","                    else:\n","                        coder_dict[coder][(tok_id, tok_id+1)] = [cat]\n","\n","        # Span Based Detection\n","        elif args.ds:\n","            if (start, end) in coder_dict[coder].keys():\n","                coder_dict[coder][(start, end)].append(cat)\n","            else:\n","                coder_dict[coder][(start, end)] = [cat]\n","\n","        # Span Based Correction\n","        else:\n","            # With error type classification\n","            if args.cse:\n","                if (start, end, cat, cor) in coder_dict[coder].keys():\n","                    coder_dict[coder][(start, end, cat, cor)].append(cat)\n","                else:\n","                    coder_dict[coder][(start, end, cat, cor)] = [cat]\n","            # Without error type classification\n","            else:\n","                if (start, end, cor) in coder_dict[coder].keys():\n","                    coder_dict[coder][(start, end, cor)].append(cat)\n","                else:\n","                    coder_dict[coder][(start, end, cor)] = [cat]\n","    return coder_dict\n","\n","# Input 1: A hyp dict; key is coder_id, value is dict of processed hyp edits.\n","# Input 2: A ref dict; key is coder_id, value is dict of processed ref edits.\n","# Input 3: A dictionary of the best corpus level TP, FP and FN counts so far.\n","# Input 4: Sentence ID (for verbose output only)\n","# Input 5: Command line args\n","# Output 1: A dict of the best corpus level TP, FP and FN for the input sentence.\n","# Output 2: The corresponding error type dict for the above dict.\n","def evaluate_edits(hyp_dict, ref_dict, best, sent_id, original_sentence, args, big_table):\n","    # Verbose output: display the original sentence\n","    sentence_dict = {}\n","    if args.verbose:\n","        print('{:-^40}'.format(\"\"))\n","        print(\"Original sentence \" + str(sent_id) + \": \" + original_sentence)\n","    \n","        sentence_dict[\"sent_id\"]=sent_id,\n","        sentence_dict[\"original-sentence\"]=original_sentence\n","    # Store the best sentence level scores and hyp+ref combination IDs\n","    # best_f is initialised as -1 cause 0 is a valid result.\n","    best_tp, best_fp, best_fn, best_f, best_hyp, best_ref = 0, 0, 0, -1, 0, 0\n","    best_cat = {}\n","    # Compare each hyp and ref combination\n","    for hyp_id in hyp_dict.keys():\n","        for ref_id in ref_dict.keys():\n","            # Get the local counts for the current combination.\n","            tp, fp, fn, cat_dict, vector_of_cat = compareEdits(hyp_dict[hyp_id], ref_dict[ref_id])\n","            # Compute the local sentence scores (for verbose output only)\n","            loc_p, loc_r, loc_f = computeFScore(tp, fp, fn, args.beta)\n","            # Compute the global sentence scores\n","            p, r, f = computeFScore(\n","                tp+best[\"tp\"], fp+best[\"fp\"], fn+best[\"fn\"], args.beta)\n","            # Save the scores if they are better in terms of:\n","            # 1. Higher F-score\n","            # 2. Same F-score, higher TP\n","            # 3. Same F-score and TP, lower FP\n","            # 4. Same F-score, TP and FP, lower FN\n","            if     (f \u003e best_f) or \\\n","                (f == best_f and tp \u003e best_tp) or \\\n","                (f == best_f and tp == best_tp and fp \u003c best_fp) or \\\n","                (f == best_f and tp == best_tp and fp == best_fp and fn \u003c best_fn):\n","                best_tp, best_fp, best_fn = tp, fp, fn\n","                best_f, best_hyp, best_ref = f, hyp_id, ref_id\n","                best_cat = cat_dict\n","                best_vector = vector_of_cat\n","            # Verbose output\n","            if args.verbose:\n","                # Prepare verbose output edits.\n","                hyp_verb = list(sorted(hyp_dict[hyp_id].keys()))\n","                ref_verb = list(sorted(ref_dict[ref_id].keys()))\n","                # add categories\n","                # hyp_dict[hyp_id] looks like (0, 1, \"str\")\n","                # hyp_dict[hyp_id][h] is a list, always length one, of the corresponding category\n","                hyp_verb = [h + (hyp_dict[hyp_id][h][0],) for h in hyp_verb]\n","                ref_verb = [r + (ref_dict[ref_id][r][0],) for r in ref_verb]\n","                # Ignore noop edits\n","                if not hyp_verb or hyp_verb[0][0] == -1: hyp_verb = []\n","                if not ref_verb or ref_verb[0][0] == -1: ref_verb = []\n","                # Print verbose info\n","                print('{:-^40}'.format(\"\"))\n","                print(\"SENTENCE \"+str(sent_id)+\" - HYP \"+str(hyp_id)+\" - REF \"+str(ref_id))\n","                print(\"HYPOTHESIS EDITS :\", hyp_verb)\n","                print(\"REFERENCE EDITS  :\", ref_verb)\n","                print(\"Local TP/FP/FN   :\", str(tp), str(fp), str(fn))\n","                print(\"Local P/R/F\"+str(args.beta)+\"  :\", str(loc_p), str(loc_r), str(loc_f))\n","                print(\"Global TP/FP/FN  :\", str(tp+best[\"tp\"]), str(fp+best[\"fp\"]), str(fn+best[\"fn\"]))\n","                print(\"Global P/R/F\"+str(args.beta)+\"  :\", str(p), str(r), str(f))\n","                print(\" \".join(best_vector))\n","                sentence_dict[f'hyp{str(hyp_id)}-edits']= hyp_verb\n","                sentence_dict[f'ref{str(ref_id)}-edits'] = ref_verb\n","                sentence_dict['best_vector_of_cat'] = best_vector\n","\n","    # Verbose output: display the best hyp+ref combination\n","    if args.verbose:\n","        print('{:-^40}'.format(\"\"))\n","        print(\"^^ HYP \"+str(best_hyp)+\", REF \"+str(best_ref)+\" chosen for sentence \"+str(sent_id))\n","        print(\"Local results:\")\n","        header = [\"Category\", \"TP\", \"FP\", \" FN\"]\n","        body = [[k, *v] for k, v in best_cat.items()]\n","        print_table([header] + body)\n","    # Save the best TP, FP and FNs as a dict, and return this and the best_cat dict\n","    best_dict = {\"tp\":best_tp, \"fp\":best_fp, \"fn\":best_fn}\n","    sentence_dict[f'best-tp'] = best_tp\n","    sentence_dict[f'best-fp']  = best_fp\n","    sentence_dict['best-fn'] = best_fn\n","    sentence_dict['best_ref'] = best_ref\n","    big_table.append(sentence_dict)\n","    return best_dict, best_cat\n","\n","# Input 1: A dictionary of hypothesis edits for a single system.\n","# Input 2: A dictionary of reference edits for a single annotator.\n","# Output 1-3: The TP, FP and FN for the hyp vs the given ref annotator.\n","# Output 4: A dictionary of the error type counts.\n","def compareEdits(hyp_edits, ref_edits):\n","    tp = 0    # True Positives\n","    fp = 0    # False Positives\n","    fn = 0    # False Negatives\n","    cat_dict = {} # {cat: [tp, fp, fn], ...}\n","    vector_of_cat = [] # [\"tp\", \"fp\", \"fp\", \"fn\", ...]\n","    \n","\n","    for h_edit, h_cats in hyp_edits.items():\n","        # noop hyp edits cannot be TP or FP\n","        if h_cats[0] == \"noop\": continue\n","        # TRUE POSITIVES\n","        if h_edit in ref_edits.keys():\n","            # On occasion, multiple tokens at same span.\n","            for h_cat in ref_edits[h_edit]: # Use ref dict for TP\n","                tp += 1\n","                vector_of_cat.append(\"tp\")\n","                # Each dict value [TP, FP, FN]\n","                if h_cat in cat_dict.keys():\n","                    cat_dict[h_cat][0] += 1\n","                else:\n","                    cat_dict[h_cat] = [1, 0, 0] #Andre: what does it do?\n","        # FALSE POSITIVES\n","        else:\n","            # On occasion, multiple tokens at same span.\n","            for h_cat in h_cats:\n","                fp += 1\n","                vector_of_cat.append(\"fp\")\n","                # Each dict value [TP, FP, FN]\n","                if h_cat in cat_dict.keys():\n","                    cat_dict[h_cat][1] += 1\n","                else:\n","                    cat_dict[h_cat] = [0, 1, 0]\n","    for r_edit, r_cats in ref_edits.items():\n","        # noop ref edits cannot be FN\n","        if r_cats[0] == \"noop\": continue\n","        # FALSE NEGATIVES\n","        if r_edit not in hyp_edits.keys():\n","            # On occasion, multiple tokens at same span.\n","            for r_cat in r_cats:\n","                fn += 1\n","                vector_of_cat.append(\"fn\")\n","                # Each dict value [TP, FP, FN]\n","                if r_cat in cat_dict.keys():\n","                    cat_dict[r_cat][2] += 1\n","                else:\n","                    cat_dict[r_cat] = [0, 0, 1]\n","\n","    return tp, fp, fn, cat_dict, vector_of_cat\n","\n","# Input 1-3: True positives, false positives, false negatives\n","# Input 4: Value of beta in F-score.\n","# Output 1-3: Precision, Recall and F-score rounded to 4dp.\n","def computeFScore(tp, fp, fn, beta):\n","    p = float(tp)/(tp+fp) if fp else 1.0\n","    r = float(tp)/(tp+fn) if fn else 1.0\n","    f = float((1+(beta**2))*p*r)/(((beta**2)*p)+r) if p+r else 0.0\n","    return round(p, 4), round(r, 4), round(f, 4)\n","\n","# Input 1-2: Two error category dicts. Key is cat, value is list of TP, FP, FN.\n","# Output: The dictionaries combined with cumulative TP, FP, FN.\n","def merge_dict(dict1, dict2):\n","    for cat, stats in dict2.items():\n","        if cat in dict1.keys():\n","            dict1[cat] = [x+y for x, y in zip(dict1[cat], stats)]\n","        else:\n","            dict1[cat] = stats\n","    return dict1\n","\n","# Input 1: A dict; key is error cat, value is counts for [tp, fp, fn]\n","# Input 2: Integer value denoting level of error category granularity.\n","# 1: Operation tier; e.g. M, R, U.  2: Main tier; e.g. NOUN, VERB  3: Everything.\n","# Output: A dictionary of category TP, FP and FN based on Input 2.\n","def processCategories(cat_dict, setting):\n","    # Otherwise, do some processing.\n","    proc_cat_dict = {}\n","    for cat, cnt in cat_dict.items():\n","        if cat == \"UNK\":\n","            proc_cat_dict[cat] = cnt\n","            continue\n","        # M, U, R or UNK combined only.\n","        if setting == 1:\n","            if cat[0] in proc_cat_dict.keys():\n","                proc_cat_dict[cat[0]] = [x+y for x, y in zip(proc_cat_dict[cat[0]], cnt)]\n","            else:\n","                proc_cat_dict[cat[0]] = cnt\n","        # Everything without M, U or R.\n","        elif setting == 2:\n","            if cat[2:] in proc_cat_dict.keys():\n","                proc_cat_dict[cat[2:]] = [x+y for x, y in zip(proc_cat_dict[cat[2:]], cnt)]\n","            else:\n","                proc_cat_dict[cat[2:]] = cnt\n","        # All error category combinations\n","        else:\n","            return cat_dict\n","    return proc_cat_dict\n","\n","# Input 1: A dict of global best TP, FP and FNs\n","# Input 2: A dict of error types and counts for those TP, FP and FNs\n","# Input 3: Command line args\n","def print_results(best, best_cats, args):\n","    category_df = []\n","    total_results = {}\n","    # Prepare output title.\n","    if args.dt: title = \" Token-Based Detection \"\n","    elif args.ds: title = \" Span-Based Detection \"\n","    elif args.cse: title = \" Span-Based Correction + Classification \"\n","    else: title = \" Span-Based Correction \"\n","\n","    # Category Scores\n","    if args.cat:\n","        best_cats = processCategories(best_cats, args.cat)\n","        print(\"\")\n","        print('{:=^66}'.format(title))\n","        print(\"Category\".ljust(24), \"TP\".ljust(8), \"FP\".ljust(8), \"FN\".ljust(8),\n","            \"P\".ljust(8), \"R\".ljust(8), \"F\"+str(args.beta))\n","        for cat, cnts in sorted(best_cats.items()):\n","            cat_p, cat_r, cat_f = computeFScore(cnts[0], cnts[1], cnts[2], args.beta)\n","            print(cat.ljust(24), str(cnts[0]).ljust(8), str(cnts[1]).ljust(8),\n","                str(cnts[2]).ljust(8), str(cat_p).ljust(8), str(cat_r).ljust(8), cat_f)\n","            cat_dict = {'Category':cat,\n","                        'TP' : cnts[0],\n","                        'FP' : cnts[1],\n","                        'FN' : cnts[2],\n","                        'P' : cat_p,\n","                        'R' : cat_r,\n","                        'F' : cat_f}\n","            category_df.append(cat_dict)\n","\n","\n","    # Print the overall results.\n","    print(\"\")\n","    print('{:=^46}'.format(title))\n","    print(\"\\t\".join([\"TP\", \"FP\", \"FN\", \"Prec\", \"Rec\", \"F\"+str(args.beta)]))\n","    print(\"\\t\".join(map(str, [best[\"tp\"], best[\"fp\"],\n","        best[\"fn\"]]+list(computeFScore(best[\"tp\"], best[\"fp\"], best[\"fn\"], args.beta)))))\n","    print('{:=^46}'.format(\"\"))\n","    print(\"\")\n","    eval = list(computeFScore(best[\"tp\"], best[\"fp\"], best[\"fn\"], args.beta))\n","    total_results =  {'TP':best[\"tp\"],\n","                      'FP':best['fp'],\n","                      'FN':best['fn'],\n","                      'Prec': eval[0],\n","                      'Rec': eval[1],\n","                      'F0.5':eval[2]}\n","    category_df = pd.DataFrame(category_df)\n","    return category_df, total_results\n","\n","def print_table(table):\n","    longest_cols = [\n","        (max([len(str(row[i])) for row in table]) + 3)\n","        for i in range(len(table[0]))\n","    ]\n","    row_format = \"\".join([\"{:\u003e\" + str(longest_col) + \"}\" for longest_col in longest_cols])\n","    for row in table:\n","        print(row_format.format(*row))\n","\n","def append_table(table, big_table):\n","  big_table.append(table)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":13,"status":"aborted","timestamp":1678467262360,"user":{"displayName":"Ukramarly","userId":"12331974385466066517"},"user_tz":300},"id":"uqLBRUeEQsS6"},"outputs":[],"source":["def main(args):\n","    big_table = []\n","    # Parse command line args\n","    # Open hypothesis and reference m2 files and split into chunks\n","    hyp_m2 = open(args.hyp).read().strip().split(\"\\n\\n\")\n","    ref_m2 = open(args.ref).read().strip().split(\"\\n\\n\")\n","    # Make sure they have the same number of sentences\n","    assert len(hyp_m2) == len(ref_m2)\n","\n","    # Store global corpus level best counts here\n","    best_dict = Counter({\"tp\":0, \"fp\":0, \"fn\":0})\n","    best_cats = {}\n","    # Process each sentence\n","    sents = zip(hyp_m2, ref_m2)\n","    for sent_id, sent in enumerate(sents):\n","        # Simplify the edits into lists of lists\n","        hyp_edits = simplify_edits(sent[0])\n","        ref_edits = simplify_edits(sent[1])\n","        # Process the edits for detection/correction based on args\n","        hyp_dict = process_edits(hyp_edits, args)\n","        ref_dict = process_edits(ref_edits, args)\n","        # original sentence for logging\n","        original_sentence = sent[0][2:].split(\"\\nA\")[0]\n","        # Evaluate edits and get best TP, FP, FN hyp+ref combo.\n","        count_dict, cat_dict = evaluate_edits(\n","            hyp_dict, ref_dict, best_dict, sent_id, original_sentence, args, big_table)\n","        # Merge these dicts with best_dict and best_cats\n","        best_dict += Counter(count_dict)\n","        best_cats = merge_dict(best_cats, cat_dict)\n","    # Print results\n","    category_df, total_results = print_results(best_dict, best_cats, args)\n","    #not saving dfs for now\n","    big_table = pd.DataFrame(big_table)\n","    return category_df, total_results, big_table"]},{"cell_type":"markdown","metadata":{"id":"pHUaW-k-hppC"},"source":["## evaluate"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":12,"status":"aborted","timestamp":1678467262360,"user":{"displayName":"Ukramarly","userId":"12331974385466066517"},"user_tz":300},"id":"J7TktpoOTLm-"},"outputs":[],"source":["category_df, total_results, big_table = main(args)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":12,"status":"aborted","timestamp":1678467262360,"user":{"displayName":"Ukramarly","userId":"12331974385466066517"},"user_tz":300},"id":"vMWHuM_1UnPA"},"outputs":[],"source":["category_df.to_csv(output_folder + f'/{model_name}-category-data.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":12,"status":"aborted","timestamp":1678467262360,"user":{"displayName":"Ukramarly","userId":"12331974385466066517"},"user_tz":300},"id":"ZzPQCtsDUCDO"},"outputs":[],"source":["# Parse command line args\n","def parse_args():\n","    parser = argparse.ArgumentParser(\n","        description=\"Calculate F-scores for error detection and/or correction.\\n\"\n","            \"Flags let you evaluate at different levels of granularity.\",\n","        formatter_class=argparse.RawTextHelpFormatter,\n","        usage=\"%(prog)s [options] -hyp HYP -ref REF\")\n","    parser.add_argument(\n","        \"-hyp\",\n","        help=\"A hypothesis M2 file.\",\n","        required=True)\n","    parser.add_argument(\n","        \"-ref\",\n","        help=\"A reference M2 file.\",\n","        required=True)\n","    parser.add_argument(\n","        \"-b\",\n","        \"--beta\",\n","        help=\"Value of beta in F-score. (default: 0.5)\",\n","        default=0.5,\n","        type=float)\n","    parser.add_argument(\n","        \"-v\",\n","        \"--verbose\",\n","        help=\"Print verbose output.\",\n","        action=\"store_true\")\n","    eval_type = parser.add_mutually_exclusive_group()\n","    eval_type.add_argument(\n","        \"-dt\",\n","        help=\"Evaluate Detection in terms of Tokens.\",\n","        action=\"store_true\")\n","    eval_type.add_argument(\n","        \"-ds\",\n","        help=\"Evaluate Detection in terms of Spans.\",\n","        action=\"store_true\")\n","    eval_type.add_argument(\n","        \"-cs\",\n","        help=\"Evaluate Correction in terms of Spans. (default)\",\n","        action=\"store_true\")\n","    eval_type.add_argument(\n","        \"-cse\",\n","        help=\"Evaluate Correction in terms of Spans and Error types.\",\n","        action=\"store_true\")\n","\n","    parser.add_argument(\n","        \"-cat\",\n","        help=\"Show error category scores.\\n\"\n","            \"1: Only show operation tier scores; e.g. R.\\n\"\n","            \"2: Only show main tier scores; e.g. NOUN.\\n\"\n","            \"3: Show all category scores; e.g. R:NOUN.\",\n","        choices=[1, 2, 3],\n","        type=int)\n","    args = parser.parse_args()\n","    return args"]},{"cell_type":"markdown","metadata":{"id":"Pw2HG6V_y9SU"},"source":["# Generate results to submit"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":201},"executionInfo":{"elapsed":1680,"status":"error","timestamp":1678467722467,"user":{"displayName":"Ukramarly","userId":"12331974385466066517"},"user_tz":300},"id":"xwU1WHGny-tY","outputId":"e169e7d8-a4cd-4e14-85ee-f1f720dcb009"},"outputs":[{"ename":"NameError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-19-6fcefe695096\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/UNLP/test-gec-fluency/test.src.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 3\u001b[0;31m \u001b[0mtest_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'translator' is not defined"]}],"source":["with open(\"/content/drive/MyDrive/UNLP/test-gec-fluency/test.src.txt\", 'r') as f:\n","    test_data = [line[:-1] for line in f.readlines()]\n","test_out = translator(test_data, batch_size=16)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":12,"status":"aborted","timestamp":1678467262360,"user":{"displayName":"Ukramarly","userId":"12331974385466066517"},"user_tz":300},"id":"3iDCIEU03wXj"},"outputs":[],"source":["!pip install stanza==1.4.2 \u0026\u003e /dev/null\n","# provided tokenizer\n","import stanza\n","\n","def tokenize(text):\n","    if not hasattr(tokenize, \"nlp\"):\n","        tokenize.nlp = stanza.Pipeline(\n","            lang=\"uk\",\n","            processors=\"tokenize\",\n","            download_method=stanza.DownloadMethod.REUSE_RESOURCES,\n","        )\n","    nlp = tokenize.nlp\n","\n","    tokenized = \" \".join([t.text for t in nlp(text).iter_tokens()])\n","    return tokenized"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":13,"status":"aborted","timestamp":1678467262361,"user":{"displayName":"Ukramarly","userId":"12331974385466066517"},"user_tz":300},"id":"Mo4s5jbB3uKt"},"outputs":[],"source":["output_sentences = [tokenize(sent['translation_text']) + '\\n' for sent in test_out]\n","\n","model_name = model_checkpoint.split('/')[1]\n","output_folder = f'/content/drive/MyDrive/UNLP/competition-outputs/{model_name}'\n","\n","import os\n","# creating the output folder\n","if not os.path.exists(output_folder):\n","  os.mkdir(output_folder)\n","\n","with open(output_folder+'/test.tgt.tok', 'w') as f:\n","  f.writelines(output_sentences)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":13,"status":"aborted","timestamp":1678467262361,"user":{"displayName":"Ukramarly","userId":"12331974385466066517"},"user_tz":300},"id":"A-wCiztgk--p"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyN3psmgVmBtRSxX9hg/TOgy","collapsed_sections":["P38z1_jME-Ea"],"mount_file_id":"1MT_ojlG1Bt9vAR6yxigjSLpcYHTiLSj3","name":"","version":""},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0139ccf77fef4c2bafcaf9b7d3fcf404":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e587f7ef430046c3bc6aa92af94541a3","IPY_MODEL_c08033f255ca413d9ab4d6dbb9ebf00e","IPY_MODEL_9729e5c8c9a54733ae89058bf3356a21"],"layout":"IPY_MODEL_7328f64f237546188f519a17a14d16c2"}},"034056713c8c41e78925b643890f2b1c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0369340f42cb47f79e3e62898a37b547":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7037511833a54512a48f46ed63477723","IPY_MODEL_ef1dc3f0e01b4bae908f4a671f396c0a","IPY_MODEL_6900cbf3baad4d47a02b42e635c9d698"],"layout":"IPY_MODEL_227e1a9af9e54a1a84899b2dd99731fb"}},"0c3ea14529a14a558f8a07dd3ea28dfb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0dd2db95d73a417da80f7937a7319283":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"12331cb3cdca409f894452a97414bdc1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b5098a1333ad44838e9a95d59173e312","max":1408,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0c3ea14529a14a558f8a07dd3ea28dfb","value":1408}},"12492f27ab764c678e72369a9a84a743":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1935352a0bdf4b989fc8150f0d69225b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a5dcf25545fe438e9064376bccc44dfa","IPY_MODEL_9e94eb73fded4634920d3abfa1eb5f97","IPY_MODEL_62a0bd980d47454fba4e2489ee8b9db5"],"layout":"IPY_MODEL_9a5158323584459091b160b520434770"}},"19cb2e7614ab461ba55dd5bee3b6ca8f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1afbedfdb8af46b0bb7b0aa9601bfc97":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d75c1b9abd72430fb90a136fd453ca17","placeholder":"​","style":"IPY_MODEL_526223b69ff74226b0ab4534b2e6d66a","value":"Downloading https://huggingface.co/stanfordnlp/stanza-uk/resolve/v1.4.1/models/tokenize/iu.pt: 100%"}},"1e67e592403e46369751f5f3f4ffbddb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a7f17a9cc1274faf8a10c8eec484e25a","placeholder":"​","style":"IPY_MODEL_41479da4ffd54b6aa88087e65f5f3413","value":"Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.1.json: "}},"227e1a9af9e54a1a84899b2dd99731fb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"247fd316835649c9bb5c4f2709abc3a1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"356d1d3ec2c9409580760c03d0a388c6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"35b690e3b69446809673ab596743dfd6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3a80334cf763422ab637b66e5cd4aac2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3c236147c43c41e1b357fe33a8a1013c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41479da4ffd54b6aa88087e65f5f3413":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4bf125487f274d9981abf1e3bf864c7c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"526223b69ff74226b0ab4534b2e6d66a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5ad8fc0c6cf94b3cbd36eb589ec67c70":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1e67e592403e46369751f5f3f4ffbddb","IPY_MODEL_9fe778c525f24075aacdca7fe8f6b201","IPY_MODEL_b4123efa501547869158281805510772"],"layout":"IPY_MODEL_e7bcab9aed7043e385d539441985b0a1"}},"5f39eb8e2fa349e18856276705250bba":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"601071dda48846238de552631be4753e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"60effddcbbb642579344c368aaa356b5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"62a0bd980d47454fba4e2489ee8b9db5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6a62f129009a4ee48ae211e6eb2c8938","placeholder":"​","style":"IPY_MODEL_9d9baa013e114cc3ae34b3baaee0d277","value":" 193k/? [00:00\u0026lt;00:00, 6.76MB/s]"}},"676438e8a7ba4053ae097350dbe87253":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"68e78f8fc7e44510be8e8d9720e88b72":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6900cbf3baad4d47a02b42e635c9d698":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f14acdd91e1a40a98cdf79d18ee63605","placeholder":"​","style":"IPY_MODEL_35b690e3b69446809673ab596743dfd6","value":" 2.44G/2.44G [01:51\u0026lt;00:00, 22.4MB/s]"}},"6a62f129009a4ee48ae211e6eb2c8938":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6dfad16fe74f46e190b4074201196a2a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_68e78f8fc7e44510be8e8d9720e88b72","placeholder":"​","style":"IPY_MODEL_676438e8a7ba4053ae097350dbe87253","value":" 1.41k/1.41k [00:00\u0026lt;00:00, 10.2kB/s]"}},"7037511833a54512a48f46ed63477723":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_247fd316835649c9bb5c4f2709abc3a1","placeholder":"​","style":"IPY_MODEL_a15c07a395a1487f8890a7382434a4bc","value":"Downloading pytorch_model.bin: 100%"}},"7328f64f237546188f519a17a14d16c2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7618bd77359845968b81af429c7c7fe7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"79a4d43981e841d182235b1192c31b9a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c236147c43c41e1b357fe33a8a1013c","placeholder":"​","style":"IPY_MODEL_7d8743daabea4df581005d50b1454fe0","value":" 646k/646k [00:00\u0026lt;00:00, 906kB/s]"}},"7d8743daabea4df581005d50b1454fe0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7f88979da4804e5fa1348e8300b9e18c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84180ddb338b427fa6e5562e620fd90e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8a6949354e804c43a0cb1609b100b008":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1afbedfdb8af46b0bb7b0aa9601bfc97","IPY_MODEL_91a38b542a774251b28a3897967a8f60","IPY_MODEL_79a4d43981e841d182235b1192c31b9a"],"layout":"IPY_MODEL_601071dda48846238de552631be4753e"}},"8b4c646f13c2405dbc3af262d0ac6329":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8b9b913b061d4da8ae34a35d67ef373c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"91a38b542a774251b28a3897967a8f60":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d0be5ae1d9264aca869c830123a76d74","max":645628,"min":0,"orientation":"horizontal","style":"IPY_MODEL_034056713c8c41e78925b643890f2b1c","value":645628}},"967024393f7c44609072cea8ac91c843":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9729e5c8c9a54733ae89058bf3356a21":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d118d7b914fe474384444d026ca49d2d","placeholder":"​","style":"IPY_MODEL_3a80334cf763422ab637b66e5cd4aac2","value":" 552k/552k [00:00\u0026lt;00:00, 617kB/s]"}},"9a5158323584459091b160b520434770":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d9baa013e114cc3ae34b3baaee0d277":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9e75f7891a6d49d189f5f2522b94ac33":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e94eb73fded4634920d3abfa1eb5f97":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_19cb2e7614ab461ba55dd5bee3b6ca8f","max":28918,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7618bd77359845968b81af429c7c7fe7","value":28918}},"9fe778c525f24075aacdca7fe8f6b201":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f88979da4804e5fa1348e8300b9e18c","max":28918,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5f39eb8e2fa349e18856276705250bba","value":28918}},"a15c07a395a1487f8890a7382434a4bc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a5dcf25545fe438e9064376bccc44dfa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_967024393f7c44609072cea8ac91c843","placeholder":"​","style":"IPY_MODEL_60effddcbbb642579344c368aaa356b5","value":"Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.1.json: "}},"a7f17a9cc1274faf8a10c8eec484e25a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab42b4d027324e029bad93461dde0de1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b4123efa501547869158281805510772":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ab42b4d027324e029bad93461dde0de1","placeholder":"​","style":"IPY_MODEL_84180ddb338b427fa6e5562e620fd90e","value":" 193k/? [00:00\u0026lt;00:00, 6.50MB/s]"}},"b5098a1333ad44838e9a95d59173e312":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b52b5e61f244473890a45546896c909b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f68bb965c27b4f3db6fe80922b9ac328","IPY_MODEL_12331cb3cdca409f894452a97414bdc1","IPY_MODEL_6dfad16fe74f46e190b4074201196a2a"],"layout":"IPY_MODEL_4bf125487f274d9981abf1e3bf864c7c"}},"c08033f255ca413d9ab4d6dbb9ebf00e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fa85941d413f4feb9fa8dd8b3def8d01","max":551526,"min":0,"orientation":"horizontal","style":"IPY_MODEL_12492f27ab764c678e72369a9a84a743","value":551526}},"d0be5ae1d9264aca869c830123a76d74":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d118d7b914fe474384444d026ca49d2d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d75c1b9abd72430fb90a136fd453ca17":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e587f7ef430046c3bc6aa92af94541a3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8b9b913b061d4da8ae34a35d67ef373c","placeholder":"​","style":"IPY_MODEL_8b4c646f13c2405dbc3af262d0ac6329","value":"Downloading https://huggingface.co/stanfordnlp/stanza-uk/resolve/v1.4.1/models/mwt/iu.pt: 100%"}},"e7bcab9aed7043e385d539441985b0a1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef1dc3f0e01b4bae908f4a671f396c0a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9e75f7891a6d49d189f5f2522b94ac33","max":2444694045,"min":0,"orientation":"horizontal","style":"IPY_MODEL_356d1d3ec2c9409580760c03d0a388c6","value":2444694045}},"f14acdd91e1a40a98cdf79d18ee63605":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f68bb965c27b4f3db6fe80922b9ac328":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ffd0cfafc4974157be057124cdfa22fd","placeholder":"​","style":"IPY_MODEL_0dd2db95d73a417da80f7937a7319283","value":"Downloading (…)lve/main/config.json: 100%"}},"fa85941d413f4feb9fa8dd8b3def8d01":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ffd0cfafc4974157be057124cdfa22fd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}